All servers have limits as to how much processing they can perform

Example:
	- Client makes a request for content
	- Server responds by providing the appropriate HTML, CCSS, JavaScript and image files

Things are more complex because the server has to check that the request is authorised, locate files within its directories, read the content of the files and prepare them for transmission to the network

If content has to be encrypted then the workload for the processor is even greater

As more and more users request pages, the workload for the processor increases until the point is reached that the processor is running flat out
At this point further request are placed in a queue until they can be processed
If the queue is full then the server may respond with a 'busy' message telling the user to try again

Although special equipment exists to offload task such as decryption and encryption and serving images, eventually any web server can be overwhelmed if too many request are received
In fact, overwhelming the server is the basis of a distributed denial of service (DDoS) attack

One solution is to provide more processing power through the technique known as scaling-out, in which multiple web servers operate in parallel to share the workload
The apportioniing of the workload is handled by a load balancer

The load balancer receives all the incoming request and redirects them to one of the attached web servers
The orginial load balancers used a simple algorithm to apportion work known as 'round robin' in which requests were assigned sequentially in order of arrival, so request 1 to server 1, and so on, circulating requests to the three servers

The simple work-sharing algortihms work well until one of the web servers fails, then it just keeps sending direct work to a failed server

Current load balancers are able to monitor the connected web servers and exclude any that have appeared to fail
Since this increases the workload on those that remain, a user may experience some degradation in service, but at least there is a response

Scaling out also increases the availability of the website, the probabiltiy that the site is available for use, because the website remains accessible even though not atll the web servers are functional

A= Uptime/ Uptime+Downtime

where Uptime is the period of time the system is operational
where Downtime is the period of time the system is non-operational
Availabiliity is A

An essential requirement for scaling-out is that any request can be fulfilled by any server, so developers must ensure that applications are 'stateless',  rather than rely on the server to remember the state of the application from a previous target

Think of the 'state' as the contents of a shopping basket. 
If that is held on a single server then all requests must be directed to that same server, else the applicaton fails
Cookies are commonly employed to carry the 'state' back and forth with each request and response, but there are limits to the size of a cookie
Another option is to save the 'state' in a shared database and use the cookie to carry an identifier for the users data