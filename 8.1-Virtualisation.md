- Virtualisation is the core technology of the cloud and has emerged as a result of improvements in the design of processor chips. Every since the 'chips' were first created, producers have been able to place more components onto a square millimeter of silicon and use those components to create computers that are faster and contain more processing power

- The recent growth of raw processing power, as provided by faster processing speeds, multi-processor and multi-core processors, means that the typical single-application server is under-utilised, running at less than 10–15% of its potential (Golden, 2009).

- The solution touted to solve both rising costs of maintenance and under-utilisation of the single application server is ‘virtualisation’, in which a special layer of software separates and secures multiple applications within a single physical host. The two forms of virtualisation commonly employed in the cloud are virtual machines and containers.

**Virtual Machines**

- The virtual machine form of virtualisation takes the resources of a single physical host computer and shares them between multiple guest computers
- Each guest appears to be an independent, self-contained computer with its own processor, memory and peripherals, running a standard operating system
![kllllllllll.JPG](../../_resources/kllllllllll.JPG)
The links between blocks of memory represent the exchange of data between different programs
The links between the drivers and the I/O devices represent the data bus that carries the input and output data

There is no direct link between the application and the input/output device
Instead, application requests operating system to complete task
In turn, operating system requests low-level drivers to perform the actual data transfer

Next model is a computer supporting a pair of virtualized servers 

![dfasfdaffa.JPG](../../_resources/dfasfdaffa.JPG)

The virtualisation softare, or hypevisor, provides the code to manage and protect the virtual servers, together with the code for the device drivers.
It is responsible for creating each virtual server, portecting a virtual server's memory space from other virtual servers, schedling usage of the processors and cleaning up when a virtual server is disposed of

Contained within each virtual server is the code for a 'guest' operating system (guest OS) and its associated application
The guest OS is responsible for managing its own application
However the device drivers of the guest OS have been replaced with 'virtual drivers'
They are virtual because they do not directly control any input/output devices
A single guest OS cant be allowed direct control because the input/output devices are shared by all the virtual servers.
When a guest OS wants to use any input/output, it makes a request to the corresponding virtual driver, which in turn makes a request thorugh the hypervisor to a real driver

Virtualisation overcomes the poor utilisation of server resources by enabling a single host ot support multiple guests
Rather than a web server requiring its own physical computer, it can now be combined with ohter web servers on a single host with the hypervisor scheduling use of the available resources between the guests

Another useful feature of virtualisation is the ability to define guest configurations, in terms of:
	- Processors
	- Memory and disk
For example:
	- simple web server hosting static content might be configured with a single virtual central processing unit and 512MB of memory
	- whereas a web server hosting PHP might be configuerd with two vCPUs and 2GB of memory
	- each configuration can be saved on disk as a VM image and loaded multiple times to create the required number of virtual machines


**Containers**
Virtual machines come with significant overhead, the entire operating system, has to be loaded before any application can start
A guest OS consumes a lot of memory to store the code that will manage memory, schedule processes, buffer disk drive reads and writes and communicate over a network
Loading a full virtual machine image from storage also takes time as it has to go through the full 'boot-up' procedure

The solution to overcome the resource and time overhead is the application container, essentially a file containing an application and associated libraries
The important difference is that an application container has no separate operating system and is, therefore, much smaller
![dsfs.JPG](../../_resources/dsfs.JPG)
The 'Container Management' layer represents teh software that manages load and unload containers, drawing on the operating system's features to isolate and secure the individual applications
However, the level of isolation between the host and container is not as strong as hypervisor-based virtualisation becasue all the contrainers share access to the host

A significant advantage of containers is that they have direct access to device drivers through the operating system, rather than the virtual device solution required for a fully virtualised machine, which helps to speed up input/output operations

Further benefits derive from the minimal administrative worklaod of creating and deploying a container
A full virtual machine requires that the operating system be properly configured for security, user accounts created and the file system protected and, if any of these are missed, the system is vulnerable to attack
Using containers means that this workload is undertaken just once

Docker is one of the most popular application containerisation tools and is gaining support amongst industry leaders such as Amazon, Google, and Microsoft
The goal of current collaborative development is to ensure that a Dcoker container can be migrated to any operating system that supports the Docker software, which should enable cloud service tenants to avoid lock-in to a single cloud provider

Next figure illustrates the various software compoonents for Vm based and container based solutions represented in a layered model
In the VM model, each VM requires a guest OS, even though two of the VMs run the same application
In the container model, if two containers run the same application, they can share any common functionality, such as the middleware represented by the 'Bin/Libs' layer
![fdsafafaa.JPG](../../_resources/fdsafafaa.JPG)
To summarise, containers are small and are therefore fast to load, and because there is no boot-up stage, they are fast to start
The size advantage means that a single host could support more containers than VM images
According to OpenStack developers, 'Instead of running a dozen or two dozen virtual machines per server, its possible to run hundreds of application containers per server'







